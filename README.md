# Emotion Detection Using Multimodal Analysis
ðŸ“˜ [Project Report](./Group11_EmotionDetectionUsingMultiModalAnalysis.pdf)

This project is part of a graduate-level course at George Mason University (CS688 - Machine Learning). It focuses on detecting human emotions through multimodal data sources such as facial expressions, sleep patterns, and wearable signals. The system integrates both deep learning and traditional ML techniques to recommend music based on the detected emotional state.

---

## ðŸ“Œ Features

- **Facial Emotion Detection** using OpenCV and the FER-2013 dataset  
- **Sleep Pattern Analysis** using EEG data (Sleep-EDF)  
- **Multimodal Emotion Classification** with feature fusion from facial and physiological data  
- **Music Recommendation System** based on detected emotions  
- Implemented using **Jupyter Notebooks**, **Keras**, **scikit-learn**, and **matplotlib**
