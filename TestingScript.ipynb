{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fcd849f-48bd-49d3-8d4c-09983ad7df4e",
   "metadata": {},
   "source": [
    "# Face Recognition vs Multi Modal Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41317340-c193-4a86-b91e-06d6da481236",
   "metadata": {},
   "source": [
    "# Face Recognition Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "88d58970-2a1f-409d-bfb2-ae673f9cdc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Recognition Output::\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "+----------+----------------+---------------------+\n",
      "|   Record | Ground Truth   | Predicted Emotion   |\n",
      "+==========+================+=====================+\n",
      "|        1 | Happy          | Happy               |\n",
      "+----------+----------------+---------------------+\n",
      "|        2 | Stressed       | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|        3 | Happy          | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|        4 | Happy          | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|        5 | Bored          | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|        6 | Bored          | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|        7 | Stressed       | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|        8 | Stressed       | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|        9 | Stressed       | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|       10 | Stressed       | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|       11 | Neutral        | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|       12 | Happy          | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|       13 | Happy          | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|       14 | Stressed       | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|       15 | Stressed       | Happy               |\n",
      "+----------+----------------+---------------------+\n",
      "|       16 | Happy          | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|       17 | Stressed       | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|       18 | Stressed       | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|       19 | Stressed       | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|       20 | Happy          | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|       21 | Happy          | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|       22 | Happy          | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|       23 | Stressed       | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|       24 | Stressed       | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "\n",
      "Final Accuracy: 0.50\n"
     ]
    }
   ],
   "source": [
    "def test_face_emotion_detection(csv_path):\n",
    "    test_data = pd.read_csv(csv_path)\n",
    "\n",
    "    results = []\n",
    "    for idx, row in test_data.iterrows():\n",
    "        try:\n",
    "            # Face emotion detection\n",
    "            face_emotion = detect_face_emotion_from_file(row['ImagePath'])\n",
    "            face_emotion_readable = {k: round(float(v), 2) for k, v in face_emotion.items()}\n",
    "            \n",
    "            # Map face emotion results\n",
    "            mapped_face = map_emotion_values(face_emotion, emotion_mappings['face'])\n",
    "            final_emotion = max(mapped_face, key=mapped_face.get)\n",
    "            \n",
    "            results.append({\n",
    "                \"Record\": idx + 1,\n",
    "                \"Ground Truth\": row['GroundTruthEmotion'],\n",
    "                #\"Face Model\": face_emotion_readable,\n",
    "                \"Predicted Emotion\": final_emotion\n",
    "            })\n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                \"Record\": idx + 1,\n",
    "                \"Ground Truth\": row['GroundTruthEmotion'],\n",
    "                #\"Face Model\": \"Error\",\n",
    "                \"Predicted Emotion\": \"Error\"\n",
    "            })\n",
    "\n",
    "    # Convert results to a DataFrame for a better display\n",
    "    df_results = pd.DataFrame(results)\n",
    "\n",
    "    # Display Results in a Clean Tabular Format\n",
    "    print(tabulate(\n",
    "        df_results,\n",
    "        headers=\"keys\",\n",
    "        tablefmt=\"grid\",\n",
    "        showindex=False\n",
    "    ))\n",
    "\n",
    "    # Calculate and Display Accuracy\n",
    "    valid_results = df_results[df_results[\"Predicted Emotion\"] != \"Error\"]\n",
    "    accuracy = accuracy_score(valid_results[\"Ground Truth\"], valid_results[\"Predicted Emotion\"])\n",
    "    print(f\"\\nFinal Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "\n",
    "# Run the function with the updated logic\n",
    "#initialize_models()  # Ensure models are loaded\n",
    "face_emotion_model = tf.keras.models.load_model(r'C:/Users/reeva/Desktop/690/best_model.keras')\n",
    "csv_path = 'test_data - Copy.csv'  # Replace with your actual CSV path\n",
    "print(\"Face Recognition Output::\")\n",
    "test_face_emotion_detection(csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4719625-aa65-44d9-bac2-bbf8de6e352f",
   "metadata": {},
   "source": [
    "# Multi Modal Integrated Module Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6acca4c6-6a63-4fdf-a996-51c83aec8ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face emotion model loaded successfully.\n",
      "LSTM model loaded successfully.\n",
      "Sleep emotion model loaded successfully.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "+----------+----------------+---------------------+\n",
      "|   Record | Ground Truth   | Predicted Emotion   |\n",
      "+==========+================+=====================+\n",
      "|        1 | Happy          | Happy               |\n",
      "+----------+----------------+---------------------+\n",
      "|        2 | Stressed       | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|        3 | Happy          | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|        4 | Happy          | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|        5 | Bored          | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|        6 | Bored          | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|        7 | Stressed       | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|        8 | Stressed       | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|        9 | Stressed       | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|       10 | Stressed       | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|       11 | Neutral        | Happy               |\n",
      "+----------+----------------+---------------------+\n",
      "|       12 | Happy          | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|       13 | Stressed       | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|       14 | Stressed       | Happy               |\n",
      "+----------+----------------+---------------------+\n",
      "|       15 | Stressed       | Happy               |\n",
      "+----------+----------------+---------------------+\n",
      "|       16 | Stressed       | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|       17 | Stressed       | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|       18 | Stressed       | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|       19 | Stressed       | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|       20 | Happy          | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|       21 | Happy          | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|       22 | Stressed       | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|       23 | Stressed       | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "|       24 | Stressed       | Stressed            |\n",
      "+----------+----------------+---------------------+\n",
      "\n",
      "Final Accuracy: 0.58\n"
     ]
    }
   ],
   "source": [
    "    import warnings\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import tensorflow as tf\n",
    "    import joblib\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from tabulate import tabulate\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")  # Suppress all warnings\n",
    "    \n",
    "    \n",
    "    # Initialize Models\n",
    "    def initialize_models():\n",
    "        global face_emotion_model, lstm_model, sleep_model\n",
    "    \n",
    "        # Load face emotion model\n",
    "        try:\n",
    "            face_emotion_model = tf.keras.models.load_model(r'C:/Users/reeva/Desktop/690/best_model.keras')\n",
    "            print(\"Face emotion model loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading face_emotion_model: {e}\")\n",
    "            face_emotion_model = None\n",
    "    \n",
    "        # Load LSTM model\n",
    "        try:\n",
    "            input_size = 2\n",
    "            hidden_size = 64\n",
    "            num_layers = 2\n",
    "            num_classes = 4\n",
    "            lstm_model = EmotionLSTM(input_size, hidden_size, num_layers, num_classes)\n",
    "            checkpoint = torch.load(r'C:/Users/reeva/Desktop/690/best_emotion_model.pth', map_location=torch.device('cpu'))\n",
    "            lstm_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            lstm_model.eval()\n",
    "            print(\"LSTM model loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading lstm_model: {e}\")\n",
    "            lstm_model = None\n",
    "    \n",
    "        # Load sleep model\n",
    "        try:\n",
    "            sleep_model = joblib.load(r'C:/Users/reeva/Desktop/690/sleep-edf-database-expanded-1.0.0-20241127T213628Z-001/sleep-edf-database-expanded-1.0.0/multi_label_model.joblib')\n",
    "            print(\"Sleep emotion model loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading sleep_model: {e}\")\n",
    "            sleep_model = None\n",
    "    \n",
    "    \n",
    "    # LSTM Model Definition\n",
    "    class EmotionLSTM(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout=0.5):\n",
    "            super(EmotionLSTM, self).__init__()\n",
    "            self.lstm = nn.LSTM(\n",
    "                input_size, hidden_size, num_layers,\n",
    "                batch_first=True, bidirectional=True,\n",
    "                dropout=dropout if num_layers > 1 else 0\n",
    "            )\n",
    "            self.attention = nn.Sequential(\n",
    "                nn.Linear(hidden_size * 2, 1),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "            self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "    \n",
    "        def forward(self, x):\n",
    "            lstm_out, _ = self.lstm(x)\n",
    "            attention_weights = self.attention(lstm_out)\n",
    "            attention_weights = torch.softmax(attention_weights, dim=1)\n",
    "            context = torch.sum(attention_weights * lstm_out, dim=1)\n",
    "            out = self.dropout(context)\n",
    "            out = self.fc(out)\n",
    "            return out\n",
    "    \n",
    "    \n",
    "    # Helper Functions\n",
    "    def map_emotion_values(module_values, mapping):\n",
    "        common_emotions = ['Happy', 'Sad', 'Neutral', 'Angry', 'Relaxed', 'Stressed', 'Bored']\n",
    "        mapped_values = {emotion: 0.0 for emotion in common_emotions}\n",
    "    \n",
    "        for emotion, value in module_values.items():\n",
    "            if emotion in mapping:\n",
    "                common_emotion = mapping[emotion]\n",
    "                mapped_values[common_emotion] += value\n",
    "            else:\n",
    "                print(f\"Debug: Unmapped emotion detected -> {emotion}. Defaulting to 'Neutral'.\")\n",
    "                mapped_values['Neutral'] += value  # Default to 'Neutral' for unmapped\n",
    "    \n",
    "        #print(f\"Mapped Values: {mapped_values}\")  # Debug log\n",
    "        return mapped_values\n",
    "    \n",
    "    \n",
    "    def combine_emotion_values(mapped_values_list, weights):\n",
    "        combined_values = {emotion: 0.0 for emotion in mapped_values_list[0].keys()}\n",
    "        for mapped_values, weight in zip(mapped_values_list, weights):\n",
    "            for emotion, value in mapped_values.items():\n",
    "                combined_values[emotion] += value * weight\n",
    "    \n",
    "        total = sum(combined_values.values())\n",
    "        if total > 0:\n",
    "            combined_values = {k: v / total for k, v in combined_values.items()}\n",
    "        else:\n",
    "            print(\"Debug: Combined values sum to 0.\")  # Debug log\n",
    "            combined_values['Neutral'] = 1.0\n",
    "    \n",
    "        #print(f\"Combined Values: {combined_values}\")  # Debug log\n",
    "        return combined_values\n",
    "    \n",
    "    \n",
    "    \n",
    "    def detect_face_emotion_from_file(image_path):\n",
    "        if not face_emotion_model:\n",
    "            return {'Neutral': 1.0}\n",
    "        try:\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"Error: Could not load image at {image_path}\")\n",
    "                return {'Neutral': 1.0}\n",
    "    \n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            roi_gray = cv2.resize(gray, (48, 48), interpolation=cv2.INTER_AREA)\n",
    "            roi_rgb = np.expand_dims(np.stack([roi_gray] * 3, axis=-1) / 255.0, axis=0)\n",
    "            predictions = face_emotion_model.predict(roi_rgb)[0]\n",
    "            detected_emotions = dict(zip(['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral'], predictions))\n",
    "            #print(f\"Face Detection Output: {detected_emotions}\")  # Debug log\n",
    "            return detected_emotions\n",
    "        except Exception as e:\n",
    "            print(f\"Error during face emotion detection: {e}\")\n",
    "            return {'Neutral': 1.0}\n",
    "    \n",
    "    \n",
    "    def detect_lstm_emotion(input_data):\n",
    "        if not lstm_model:\n",
    "            return {'Baseline': 1.0}\n",
    "        try:\n",
    "            tensor_data = torch.tensor(input_data, dtype=torch.float32).unsqueeze(0)\n",
    "            output = lstm_model(tensor_data)\n",
    "            probabilities = torch.softmax(output, dim=1).detach().numpy()[0]\n",
    "            detected_emotions = dict(zip(['Baseline', 'Stress', 'Amusement', 'Meditation'], probabilities))\n",
    "            #print(f\"LSTM Detection Output: {detected_emotions}\")  # Debug log\n",
    "            return detected_emotions\n",
    "        except Exception as e:\n",
    "            print(f\"Error during LSTM emotion detection: {e}\")\n",
    "            return {'Baseline': 1.0}\n",
    "    \n",
    "    def detect_sleep_emotion(input_data):\n",
    "        \"\"\"\n",
    "        Simple heuristic-based sleep emotion detection.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Example heuristic: Use the mean and range of the input data\n",
    "            mean_value = np.mean(input_data)\n",
    "            max_value = np.max(input_data)\n",
    "            min_value = np.min(input_data)\n",
    "    \n",
    "            # Assign emotions based on heuristic\n",
    "            if mean_value > 0.7:\n",
    "                return {'happiness': 1.0, 'sadness': 0.0, 'anger': 0.0, 'surprise': 0.0, 'fear': 0.0}\n",
    "            elif max_value - min_value > 0.5:\n",
    "                return {'happiness': 0.0, 'sadness': 0.0, 'anger': 1.0, 'surprise': 0.0, 'fear': 0.0}\n",
    "            elif mean_value < 0.3:\n",
    "                return {'happiness': 0.0, 'sadness': 1.0, 'anger': 0.0, 'surprise': 0.0, 'fear': 0.0}\n",
    "            else:\n",
    "                return {'happiness': 0.0, 'sadness': 0.0, 'anger': 0.0, 'surprise': 0.0, 'fear': 1.0}\n",
    "        except Exception as e:\n",
    "            print(f\"Error during sleep emotion detection heuristic: {e}\")\n",
    "            return {'happiness': 0.0, 'sadness': 0.0, 'anger': 0.0, 'surprise': 0.0, 'fear': 1.0}\n",
    "\n",
    "        \n",
    "    def test_emotion_detection(csv_path):\n",
    "        test_data = pd.read_csv(csv_path)\n",
    "    \n",
    "        results = []\n",
    "        print(\"\\n--- Emotion Detection Results ---\\n\")\n",
    "        for idx, row in test_data.iterrows():\n",
    "            try:\n",
    "                print(f\"Processing record {idx + 1}...\")\n",
    "    \n",
    "                # Face emotion detection\n",
    "                face_emotion = detect_face_emotion_from_file(row['ImagePath'])\n",
    "                print(f\"Face Emotion Output: {face_emotion}\")\n",
    "    \n",
    "                # LSTM emotion detection\n",
    "                lstm_input = list(map(float, row['LSTMInput'].strip('\"').split(',')))\n",
    "                lstm_emotion = detect_lstm_emotion([lstm_input])\n",
    "                print(f\"LSTM Emotion Output: {lstm_emotion}\")\n",
    "    \n",
    "                # Sleep emotion detection\n",
    "                sleep_input = list(map(float, row['SleepInput'].strip('\"').split(',')))\n",
    "                sleep_emotion = detect_sleep_emotion(sleep_input)\n",
    "                print(f\"Sleep Emotion Output: {sleep_emotion}\")\n",
    "    \n",
    "                # Map and Combine Results\n",
    "                mapped_face = map_emotion_values(face_emotion, emotion_mappings['face'])\n",
    "                mapped_lstm = map_emotion_values(lstm_emotion, emotion_mappings['lstm'])\n",
    "                mapped_sleep = map_emotion_values(sleep_emotion, emotion_mappings['sleep'])\n",
    "                combined = combine_emotion_values([mapped_face, mapped_lstm, mapped_sleep], [0.4, 0.4, 0.2])\n",
    "                final_emotion = max(combined, key=combined.get)\n",
    "                print(f\"final_emotion Output: {final_emotion}\")\n",
    "                results.append([idx + 1, row['GroundTruthEmotion'], final_emotion, combined])\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing record {idx + 1}: {e}\")\n",
    "                results.append([idx + 1, row['GroundTruthEmotion'], \"Error\", {}])\n",
    "    \n",
    "        # Display Results\n",
    "        headers = [\"Record\", \"Ground Truth\", \"Predicted Emotion\", \"Combined Values\"]\n",
    "        #headers = [\"Record\", \"Ground Truth\", \"Predicted Emotion\", \"Combined Values\"]\n",
    "        print(tabulate(results, headers=headers, tablefmt=\"grid\"))\n",
    "    \n",
    "        # Calculate Accuracy\n",
    "        predictions = [result[2] for result in results if result[2] != \"Error\"]\n",
    "        ground_truths = [result[1] for result in results if result[2] != \"Error\"]\n",
    "        accuracy = accuracy_score(ground_truths, predictions)\n",
    "        print(f\"\\nFinal Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "    def test_emotion_detection_readable(csv_path):\n",
    "        test_data = pd.read_csv(csv_path)\n",
    "    \n",
    "        results = []\n",
    "        for idx, row in test_data.iterrows():\n",
    "            try:\n",
    "                # Face emotion detection\n",
    "                face_emotion = detect_face_emotion_from_file(row['ImagePath'])\n",
    "                face_emotion_readable = {k: round(float(v), 2) for k, v in face_emotion.items()}\n",
    "    \n",
    "                # LSTM emotion detection\n",
    "                lstm_input = list(map(float, row['LSTMInput'].strip('\"').split(',')))\n",
    "                lstm_emotion = detect_lstm_emotion([lstm_input])\n",
    "                lstm_emotion_readable = {k: round(float(v), 2) for k, v in lstm_emotion.items()}\n",
    "    \n",
    "                # Sleep emotion detection\n",
    "                sleep_input = list(map(float, row['SleepInput'].strip('\"').split(',')))\n",
    "                sleep_emotion = detect_sleep_emotion(sleep_input)\n",
    "                sleep_emotion_readable = {k: round(float(v), 2) for k, v in sleep_emotion.items()}\n",
    "                #print(f\"Sleep Detection Output: {sleep_emotion_readable}\")\n",
    "    \n",
    "                # Map and Combine Results\n",
    "                mapped_face = map_emotion_values(face_emotion, emotion_mappings['face'])\n",
    "                mapped_lstm = map_emotion_values(lstm_emotion, emotion_mappings['lstm'])\n",
    "                mapped_sleep = map_emotion_values(sleep_emotion, emotion_mappings['sleep'])\n",
    "                combined = combine_emotion_values([mapped_face, mapped_lstm, mapped_sleep], [0.4, 0.4, 0.1])\n",
    "                final_emotion = max(combined, key=combined.get)\n",
    "    \n",
    "                results.append({\n",
    "                    \"Record\": idx + 1,\n",
    "                    \"Ground Truth\": row['GroundTruthEmotion'],\n",
    "                    #\"Face Model\": face_emotion_readable,\n",
    "                    #\"LSTM Model\": lstm_emotion_readable,\n",
    "                    #\"Sleep Model\": sleep_emotion_readable,\n",
    "                    \"Predicted Emotion\": final_emotion\n",
    "                })\n",
    "            except Exception as e:\n",
    "                results.append({\n",
    "                    \"Record\": idx + 1,\n",
    "                    \"Ground Truth\": row['GroundTruthEmotion'],\n",
    "                   # \"Face Model\": \"Error\",\n",
    "                    #\"LSTM Model\": \"Error\",\n",
    "                    #\"Sleep Model\": \"Error\",\n",
    "                    \"Predicted Emotion\": \"Error\"\n",
    "                })\n",
    "    \n",
    "        # Convert results to a DataFrame for a better display\n",
    "        df_results = pd.DataFrame(results)\n",
    "    \n",
    "        # Display Results in a Clean Tabular Format\n",
    "        print(tabulate(\n",
    "            df_results,\n",
    "            headers=\"keys\",\n",
    "            tablefmt=\"grid\",\n",
    "            showindex=False\n",
    "        ))\n",
    "    \n",
    "        # Calculate and Display Accuracy\n",
    "        valid_results = df_results[df_results[\"Predicted Emotion\"] != \"Error\"]\n",
    "        accuracy = accuracy_score(valid_results[\"Ground Truth\"], valid_results[\"Predicted Emotion\"])\n",
    "        print(f\"\\nFinal Accuracy: {accuracy:.2f}\")\n",
    "    \n",
    "    \n",
    "    # Emotion Mappings\n",
    "    emotion_mappings = {\n",
    "        \"face\": {\n",
    "            'Happy': 'Happy',\n",
    "            'Sad': 'Stressed',\n",
    "            'Neutral': 'Bored',\n",
    "            'Angry': 'Stressed',\n",
    "            'Surprise': 'Happy',  # Ensure 'Surprise' is included\n",
    "            'Disgust': 'Stressed',     # Include 'Disgust' if face model outputs it\n",
    "            'Fear': 'Stressed'\n",
    "        },\n",
    "        \"lstm\": {\n",
    "            'Baseline': 'Bored',\n",
    "            'Stress': 'Stressed',\n",
    "            'Amusement': 'Happy',\n",
    "            'Meditation': 'Happy'\n",
    "        },\n",
    "       \"sleep\": {'happiness': 'Happy', 'sadness': 'Stressed', 'anger': 'Stressed', 'surprise': 'Happy', 'Surprise': 'Happy', 'fear': 'Stressed'}\n",
    "    }\n",
    "    \n",
    "    # Initialize models and test\n",
    "    initialize_models()\n",
    "    csv_path = 'test_data.csv'  # Update with your CSV file path\n",
    "    test_emotion_detection_readable(csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7353e83-3394-4300-9f90-52a0f6fb070f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
